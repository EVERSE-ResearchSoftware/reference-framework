## 2.2 FAIR

The FAIR Guiding Principles were originally developed for scientific data management and stewardship, with the goal of improving the Findability, Accessibility, Interoperability and Reusability of digital assets. While the original FAIR principles focused primarily on data, there has been growing recognition of the need to apply FAIR principles to research software as well.

The FAIR Principles for Research Software (FAIR4RS Principles)[^2] adapt and extend the original FAIR principles to address the unique characteristics of software. Key considerations in applying FAIR to software include:

- Software's executable nature, compared to static datasets
- Software's composite structure, often involving multiple components and dependencies
- The continuous evolution and versioning of software
- The importance of source code access for true reusability
- The FAIR4RS Principles aim to make research software:
  - Findable: software and its associated metadata should be easy to find for both humans and machines
  - Accessible: software and metadata should be retrievable via standardized protocols.
  - Interoperable: software should be able to exchange data and work with other software via common formats and APIs.
  - Reusable: software should be well-described and include clear usage licenses to enable reuse, modification and integration into other software.

Key recommendations for implementing FAIR for research software include:

1. Using persistent and unique identifiers for software and its versions
2. Providing rich metadata to describe the software
3. Using open, standardized formats and protocol
4. Providing clear licensing and usage information
5. Following community standards and best practice

By applying FAIR principles, research software can become more discoverable, accessible, and reusable by both humans and machines. This supports transparency, reproducibility, and reuse in computational research.

The FAIR4RS Principles provide aspirational guidelines that software creators and maintainers can work towards incrementally. Tools and practices continue to evolve to support FAIR software across different research domains. The ReSA Actionable FAIR4RS Task Force is developing "good enough" guidelines to help make research software FAIR, based on original suggestions from the biosciences [REF].

There are some aspects of FAIRness that have a relationship to quality. For example, documentation is usually connected to better quality.

In the EOSC TF there is a table with a relationship between FAIR and Quality. We need to review and expand this. https://zenodo.org/records/10723608 Table 6.

### 2.2.1 Good enough practices

This section attempts to capture the list of the various good practices that are currently being addressed in the EVERSE project.

*This section will be further developed in the next versions of the RF.*

### 2.2.2 Examples of tools relevant for FAIR software

The following is a non-exhaustive list of tools that can help assess or improve the FAIRness of research software. For more comprehensive and up-to-date guidance on tools and services that support FAIR software principles, see the Research Software Quality Toolkit (RSQKit) and the EVERSE Tech Radar.

It's important to note that most existing FAIR software assessment tools were originally developed to assess compliance with FAIR data principles rather than the specific requirements of research software. As a result, some discernment should be used when applying these tools to evaluate a repository's compliance with the FAIR4RS principles, as software has unique characteristics—such as its executable nature, composite structure, and continuous evolution—that differ fundamentally from static datasets.

The tools listed below fall into two main categories: automated assessment tools that provide some level of FAIR evaluation, and user self-assessment tools that guide researchers through structured questionnaires. These tools provide valuable starting points for improving software FAIRness and should be used as part of a broader strategy that includes adherence to community standards, proper documentation practices, and appropriate metadata provision.

**Automated assessment tools:**

(see https://doi.org/10.5281/zenodo.13268685 for comparison between F-UJI, FAIR-enough, FAIR Checker and howfairis. None of these tools can currently be applied directly to assess a repository's compliance with the full set of FAIR4RS principles)

- Originally developed to test compliance with FAIR data principles
  - F-UJI (https://github.com/pangaea-data-publisher/fuji)
  - FAIR Checker (https://github.com/IFB-ElixirFr/FAIR-chekcer)
  - FAIR-enough (https://github.com/vemonet/fair-enough-metrics)
- Targeting research software explicitly
  - Howfairis (https://github.com/fair-software/howfairis), doesn't use FAIR4RS principles but relies on 5 recommendations for FAIR software developed by DANS
  - Extension of F-UJI by EPCC/SSI [6]

**User self-assessment based on guided questionnaires:**

- SATISFYD questionnaire for data (https://satifyd.dans.knaw.nl/)
- "Self-assessment for FAIR research software" questionnaire for FAIR4RS (https://fairsoftwarechecklist.net/v0.2/)
- Five recommendations for FAIR software (https://fair-software.nl/, does not explicitly use FAIR4RS)
- FAIR data self assessment tool (https://ardc.edu.au/resource/fair-data-self-assessment-tool/)

[^2]: FAIR Principles for Research Software (FAIR4RS Principles), https://zenodo.org/records/6623556.
